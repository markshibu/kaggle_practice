{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比 ( 直接drop非数值列  、 one-hot处理非数值列 ） \n",
    "\n",
    "1.drop 和 one-hot\n",
    "\n",
    "2.align training set & test set\n",
    "\n",
    "3.missing data 处理\n",
    "\n",
    "4.cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictors = train_data.loc[:, train_data.columns != 'SalePrice']\n",
    "target = train_data.SalePrice\n",
    "\n",
    "test_predictors = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop 和 one-hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop those non_numeric columns\n",
    "numeric_training_predictors = training_predictors.select_dtypes(exclude=[\"object\"]).drop(\"Id\",1)\n",
    "numeric_test_predictors = test_predictors.select_dtypes(exclude=[\"object\"]).drop(\"Id\",1)\n",
    "\n",
    "# One-hot\n",
    "one_hot_training_predictors = pd.get_dummies(training_predictors).drop(\"Id\",1)\n",
    "one_hot_test_predictors = pd.get_dummies(test_predictors).drop(\"Id\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### align training set & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_training_predictors, one_hot_test_predictors = one_hot_training_predictors.align(one_hot_test_predictors, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing data 处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_predictors\n",
    "from sklearn.preprocessing import Imputer\n",
    "my_imputer = Imputer()\n",
    "\n",
    "cols_with_missing = (col for col in numeric_training_predictors.columns if numeric_training_predictors[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    numeric_training_predictors[col+'_was_missing'] = numeric_training_predictors[col].isnull()\n",
    "numeric_training_predictors = my_imputer.fit_transform(numeric_training_predictors)\n",
    "\n",
    "cols_with_missing = (col for col in numeric_test_predictors.columns if numeric_test_predictors[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    numeric_test_predictors[col+'_was_missing'] = numeric_test_predictors[col].isnull()\n",
    "numeric_test_predictors = my_imputer.fit_transform(numeric_test_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_predictors\n",
    "cols_with_missing = (col for col in one_hot_training_predictors.columns if one_hot_training_predictors[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    one_hot_training_predictors[col+'_was_missing'] = one_hot_training_predictors[col].isnull()\n",
    "one_hot_training_predictors = my_imputer.fit_transform(one_hot_training_predictors)\n",
    "\n",
    "cols_with_missing = (col for col in one_hot_test_predictors.columns if one_hot_test_predictors[col].isnull().any())\n",
    "for col in cols_with_missing:\n",
    "    one_hot_test_predictors[col+'_was_missing'] = one_hot_test_predictors[col].isnull()\n",
    "one_hot_test_predictors = my_imputer.fit_transform(one_hot_test_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def get_mae(X, y):\n",
    "    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention\n",
    "    return -1 * cross_val_score(RandomForestRegressor(50), \n",
    "                                X, y, \n",
    "                                scoring = 'neg_mean_absolute_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18535.641690425688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mae(numeric_training_predictors,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18105.271256369306"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mae(one_hot_training_predictors,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
